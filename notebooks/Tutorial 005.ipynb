{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Library/Python/3.6/lib/python/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "\n",
    "def getNow():\n",
    "    now       = dt.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "    nowFolder = os.path.join('./logFolder', now)\n",
    "    return nowFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X = np.random.rand(N, 2)\n",
    "y = 2*X[:, 0] + 3*X[:, 1] + 4 + 0.1*(np.random.rand(N)-0.5)\n",
    "y = y.reshape((-1, 1))\n",
    "tMask = np.random.choice([True, False], (N,), p=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('trainData'):\n",
    "    inpTrain = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='inpTrain')\n",
    "    outTrain = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='outTrain')\n",
    "\n",
    "with tf.variable_scope('testData'):\n",
    "    inpTest = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='inpTest')\n",
    "    outTest = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='outTest')\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    W = tf.Variable(initial_value=np.random.rand(2, 1), name='W', dtype=tf.float32)\n",
    "    b = tf.Variable(initial_value=0, name='b', dtype=tf.float32)\n",
    "    \n",
    "    # Add summaries \n",
    "    # ---------------------\n",
    "    tf.summary.scalar('bSummary', b)\n",
    "    tf.summary.histogram('WSummary', W)\n",
    "    tf.summary.scalar('WMin', tf.reduce_min(W))\n",
    "    tf.summary.scalar('WMax', tf.reduce_max(W))\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        yHatTrain = tf.matmul(inpTrain,  W )+ b\n",
    "        errTrain  = tf.reduce_mean((outTrain - yHatTrain)**2, name='errTrain')\n",
    "        tf.summary.scalar('trainErr', errTrain)\n",
    "        \n",
    "    with tf.variable_scope('test'):\n",
    "        yHatTest = tf.matmul(inpTest,  W )+ b\n",
    "        errTest  = tf.reduce_mean((outTest - yHatTest)**2, name='errTest')\n",
    "        tf.summary.histogram('testErrHist', (outTest - yHatTest)**2)\n",
    "        tf.summary.scalar('testErr', errTest)\n",
    "\n",
    "with tf.variable_scope('optimizer'):\n",
    "    lr = tf.Variable(0.01, dtype=tf.float32, name='learningRate')\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(errTrain)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 40.13312911987305, Testing: 40.21525192260742\n",
      "Training: 19.561201095581055, Testing: 19.62839126586914\n",
      "Training: 8.323736190795898, Testing: 8.374462127685547\n",
      "Training: 3.0672836303710938, Testing: 3.103227138519287\n",
      "Training: 1.005989909172058, Testing: 1.0307197570800781\n",
      "Training: 0.33913254737854004, Testing: 0.3565252721309662\n",
      "Training: 0.15956372022628784, Testing: 0.17266733944416046\n",
      "Training: 0.11536970734596252, Testing: 0.12608012557029724\n",
      "Training: 0.10107550024986267, Testing: 0.11036919057369232\n",
      "Training: 0.09207272529602051, Testing: 0.10038135945796967\n",
      "Training: 0.08391036093235016, Testing: 0.09140622615814209\n",
      "Training: 0.0760197639465332, Testing: 0.08277406543493271\n",
      "Training: 0.06840521097183228, Testing: 0.07445838302373886\n",
      "Training: 0.06112736091017723, Testing: 0.06651479750871658\n",
      "Training: 0.05423999950289726, Testing: 0.05899950489401817\n",
      "Training: 0.0477842353284359, Testing: 0.05195698142051697\n",
      "Training: 0.041789766401052475, Testing: 0.04541986808180809\n",
      "Training: 0.036274489015340805, Testing: 0.039407745003700256\n",
      "Training: 0.031247027218341827, Testing: 0.033930037170648575\n",
      "Training: 0.02670690044760704, Testing: 0.028986027464270592\n",
      "Training: 0.0226456131786108, Testing: 0.0245661623775959\n",
      "Training: 0.01904776506125927, Testing: 0.0206532534211874\n",
      "Training: 0.015892453491687775, Testing: 0.017224043607711792\n",
      "Training: 0.013153638690710068, Testing: 0.0142496507614851\n",
      "Training: 0.01080198585987091, Testing: 0.01169759314507246\n",
      "Training: 0.00880550779402256, Testing: 0.009532549418509007\n",
      "Training: 0.007130550220608711, Testing: 0.007717421744018793\n",
      "Training: 0.005742659792304039, Testing: 0.0062143499962985516\n",
      "Training: 0.0046075861901044846, Testing: 0.004985767882317305\n",
      "Training: 0.003691963152959943, Testing: 0.003995188046246767\n",
      "Training: 0.0029639648273587227, Testing: 0.0032078621443361044\n",
      "Training: 0.002393950941041112, Testing: 0.002591516124084592\n",
      "Training: 0.0019547129049897194, Testing: 0.0021165756043046713\n",
      "Training: 0.0016219459939748049, Testing: 0.0017566902097314596\n",
      "Training: 0.0013742776354774833, Testing: 0.001488705980591476\n",
      "Training: 0.0011933721834793687, Testing: 0.0012928012292832136\n",
      "Training: 0.001063812873326242, Testing: 0.0011523229768499732\n",
      "Training: 0.0009729348821565509, Testing: 0.0010536124464124441\n",
      "Training: 0.0009105662466026843, Testing: 0.0009856978431344032\n",
      "Training: 0.0008687400259077549, Testing: 0.0009400022681802511\n",
      "Training: 0.0008413600153289735, Testing: 0.000909945520106703\n",
      "Training: 0.0008238856680691242, Testing: 0.000890643335878849\n",
      "Training: 0.0008130272617563605, Testing: 0.000878545397426933\n",
      "Training: 0.0008064706344157457, Testing: 0.0008711540722288191\n",
      "Training: 0.0008026270661503077, Testing: 0.0008667465299367905\n",
      "Training: 0.0008004423580132425, Testing: 0.0008641841704957187\n",
      "Training: 0.0007992413593456149, Testing: 0.0008627285133115947\n",
      "Training: 0.0007986031705513597, Testing: 0.0008619193686172366\n",
      "Training: 0.0007982766255736351, Testing: 0.0008614795515313745\n",
      "Training: 0.0007981166709214449, Testing: 0.0008612396195530891\n",
      "Training: 0.0007980398950167, Testing: 0.0008611123776063323\n",
      "Final Values\n",
      "------------------------------\n",
      "Training: 0.0007980398950167, Testing: 0.0008611123776063323\n",
      "tensorboard --logdir=./logFolder/2018-06-08--01-08-23\n"
     ]
    }
   ],
   "source": [
    "folder = getNow()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(folder, sess.graph)\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(5001):\n",
    "        sess.run( opt, feed_dict={\n",
    "            inpTrain : X[tMask, :],\n",
    "            outTrain : y[tMask, :],\n",
    "            lr       : 0.01\n",
    "             })\n",
    "        \n",
    "        if (i % 100) == 0:\n",
    "            summary, errTrainVal, errTestVal = sess.run( [merged, errTrain, errTest], feed_dict={\n",
    "                inpTrain : X[tMask, :],\n",
    "                outTrain : y[tMask, :],\n",
    "                inpTest : X[~tMask, :],\n",
    "                outTest : y[~tMask, :]})\n",
    "            \n",
    "            writer.add_summary(summary, i)\n",
    "            print('Training: {}, Testing: {}'.format(errTrainVal, errTestVal))\n",
    "            \n",
    "writer.close()\n",
    "\n",
    "print('Final Values')\n",
    "print('-'*30)\n",
    "print('Training: {}, Testing: {}'.format(errTrainVal, errTestVal))\n",
    "    \n",
    "print('tensorboard --logdir={}'.format( folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
